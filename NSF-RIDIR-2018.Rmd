---
title: "NSF-RIDIR-2018"
author: "Rick Gilmore"
date: "`r Sys.time()`"
output: 
  html_document:
    toc: true
    toc_depth: 4
    toc_float: true
    code_folding: hide
---

## NSF RIDIR 2018

These features are required for the PLAY project. 
They are described in narrative form in the (not funded) RIDIR 2018 NSF proposal. 
The narrative descriptions are provided below.

### Aim 1

**Improve the reproducibility, transparency, and scalability of video-based research via LabNanny, a web-based scientific process management (SPM) system.**

Video-based behavioral research involves a sequence of steps: multi-step workflows to collect and process multiple file types; iterative, looping steps to review, code, and conduct quality assurance on the data; tracking task assignments among various researchers/staff; and monitoring progress on project-wide recruitment, testing, coding, and analyses (Fig. 2). 
Single lab projects and large consortia face similar problems and implement similar workflows. 
But the unprecedented scale of PLAY and the commitment to openly share all data magnifies the challenges. 
Most video-based researchers depend on paper-and-pencil checklists or spreadsheets to manage files, people, processes, and tasks. In extensive piloting for PLAY, we determined that no free or open-source scientific process management (SPM) tool meets the needs of video-based research.

So we will develop “LabNanny,” a new web-based SPM. 
LabNanny will be thoroughly vetted by the 65-member PLAY Launch Group as it manages training across geographically dispersed sites, the flow of video and other data files collected across 30 sites, assignment and outcome of QA reviews, training and assignment of coding passes to 48 labs and outcome of reliability checks on coded files, cross-checking of participant metadata, and finally monitoring recruitment, coding, and data-sharing goals. 
In planning PLAY, PIs Gilmore and Adolph piloted and refined the basic workflow using ad hoc tools, thereby specifying the requirements for LabNanny. 
Moreover, although the number of participating labs in PLAY is many times larger than comparable projects, the sequence of operations required is identical to that used by single labs and smaller collaborative teams. 
Thus, in developing and deploying LabNanny, we will create, test, and refine infrastructure that will be immediately valuable to the entire community of video-using behavioral and social scientists when openly shared at the end of the grant period.

Preliminary work: 
The PIs interviewed colleagues and Project Advisory Board member Nilam Ram who have successfully conducted similar large-scale, geographically distributed research projects involving multiple data types, including video. 
We learned that most labs use a combination of checklists and spreadsheets, and sometimes a custom relational database with shared/cloud file storage. 
We evaluated whether existing project/process management tools (e.g., JIRA, Asana, Trello, ProcessStreet, ProcessMaker, ProcessMate, JBPM, Camunda, Flowable, Aquarium) might be adapted for our use. 
In so doing, we learned that none of the tools will work without substantial modification, most of the web-based tools lack the integration between tasks and files that we require, and the scale of PLAY pushes the project outside the bounds of what cloud services provide for free.

#### Project 1.1

**Workflow definition; task assignment and queuing**

We plan to fork an existing open source system—ProcessMaker is the leading candidate—and adapt and extend it to the needs of video-based research projects like PLAY. 
In forking, adapting, and extending an existing system, we must allow users to create multi-step workflows and assign tasks within workflows to people. 
We must also integrate the forked system into Databrary’s authentication/permission and user notification system. 
The result we will call LabNanny to highlight the central (and distinct) role that scientific process management and workflow management plays in robust and reproducible research. 
LabNanny will require interfaces that allow researchers to create workflows for training, data collection, QA, coding, inter-observer reliability, and data sharing (see Fig. 2). 
Should forking prove unworkable for some reason, our backup solution is to create our own SQL-style database using PostgreSQL, the core of Databrary’s current backend.

This will be available to 3 PIs…
This will be available ONLY to the databrary community ...
This will be a PLAY specific solution …
New York located PLAY staff will be using this… 
Consisting naming schemes / session IDs.
Queuing manager…
Part of volume creation … (adding people) … 
Volume Creation happens first … (Volume owner controls who has access)...
Project Volume : This virtual volume will be available to all …
Person logs on … Parent volume : child volume
Once volume / user information has been obtained… then PIs will give information on tagging… 
data collection / coding labs / consulting labs .. collaborators...

#### Project 1.2

**File management**

LabNanny must permit files to be attached to specific workflows. For example, once one of the 30 PLAY data collection labs has finished a testing session, that lab will have to upload the video, ambient sound, and questionnaire files to Databrary and assign the newly collected video for QA review by NYU-based PLAY staff (see Fig. 1A and Fig. 2). That assignment must trigger a notification to the PLAY project staff who must subsequently assign the video to a particular person for review. All files uploaded to Databrary get their own URIs (unique links) after they are transcoded into a common video format, and Databrary’s API checks file-level access permissions before showing a user a particular file. So, we will build the file management component of LabNanny alongside Databrary’s existing framework by attaching file-level URIs to specific workflow steps. This should eliminate the need to send files around like email attachments, a solution unworkable for multiple reasons (privacy, file sizes, etc.). Nevertheless, Databrary’s existing back-end is based on the constraint that a file uploaded to one dataset (project) and session (date + time + person) remains there. We will have to implement ways for the same files to progress through multiple, parallel workflows (e.g., multiple coding and review passes), while maintaining the integrity of Databrary’s project, session, and file permission structure. Our current plans involve extending Databrary’s “tagging” feature to include tags related to a given file’s status within the overall workflow (e.g., “Pending QA review”, "Transcription Completed", or “Ready to be Shared”). 

#### Project 1.3

**Progress monitoring dashboard and analytics**

For LabNanny to be an effective tool for video-centered research projects, PIs must be able to monitor progress in real time at every phase of the project, from participant recruitment, to data collection, to QA review, to coding, analysis, and ultimately data sharing. In testing LabNanny with PLAY, we will implement dashboards that will show real-time progress reports—in data collection across the 30 sites, in QA review across 900+ videos, in coding across 48+ sites, in achieving inter-observer reliability across 9000+ coding passes, and in transferring all videos, Datavyu coding spreadsheets, and related data files to the appropriate Databrary datasets for sharing. We will also implement dashboards for Launch Group PIs who collect data to monitor their own recruiting progress (including participant demographic targets), and for coding labs to monitor their lab’s progress in meeting coding goals. These monitoring and reporting tools will build on Databrary’s existing spreadsheet interfaces that capture participant characteristics (age, sex, race/ethnicity) and internal reporting functions that provide PIs with summary information about participants and sessions within a data volume.

##### Comments

participant recruitment, to data collection, to QA review, to coding, analysis, and ultimately data sharing


### Aim 2

**Accelerate data sharing by making self-curation of datasets more reliable, robust, and efficient**

To accelerate data sharing we will develop and deploy cloud-based project file sync services to enhance self-curation of video datasets. Currently, researchers must manually upload videos and associated data files to Databrary and must hand-enter participant and session-related metadata. This makes self-curation burdensome and error-prone—in the context of PLAY, 30 different labs will be collecting, uploading, and entering 30+ sessions each. Project 2 will make the ingestion and curation of research materials more reliable and efficient by creating a standard, machine-readable project structure and a local file syncing mechanism, thereby making data curation less burdensome and more reliable for all Databrary researchers.

#### Project 2.1

**Adapt BIDS to suit PLAY and video-centered research more broadly**

Preliminary work: We have consulted with Russell Poldrack, founder of the Stanford Center for Reproducible Neuroscience45,46 and Databrary Board member, and with Chris Gorgolewski, leader of the community-developed Brain Imaging Data Structure47. BIDS is an emerging standard for representing the task and analysis structure of brain imaging studies, including studies that involve measures of human behavior that have a dense temporal structure similar to video. Indeed, BIDS allows researchers to store participant, task, and measurement data in a format that is easily readable by many brain imaging data repositories. BIDS uses standard, open formats (tab-separated text files, JSON), and our consultations confirmed that the BIDS format can be readily adapted for use by Databrary. Moreover, increasing numbers of cognitive neuroscientists use video as display materials or as behavioral data streams, so cooperating on the creation of an open standard for video-centered behavioral research will pave the way for further integration among research communities and open science repositories (Project 5).

##### Comments

…. Already working on DV json format.. BIDS seems like an overkill but will still be looked at.

#### Project 2.2

**Develop a desktop extension of LabNanny for uploading video data and related metadata into Databrary**

Rather than require researchers to upload videos and enter metadata by hand, we will develop a desktop extension of LabNanny to manage file synchronization to and from Databrary. LabNanny will link specific desktop file directories or folders to a particular Databrary volume. This will keep responsibility for the control of local video files and related metadata with individual PIs to reflect the reality that security requirements may differ from institution to institution as may ethics board or IRB policies. LabNanny will verify that files stored in the target desktop directory are readable and formatted properly, then copy and enter those files into the Databrary system. Uploads can occur immediately or be scheduled for off hours when network bandwidth demands are lower. Most researchers collect participant metadata electronically using a desktop spreadsheet—PLAY will do so using a custom tablet app that will export participant metadata into a BIDS-compatible format. LabNanny will require researchers to map their individual metadata field names for a particular project to the standard Databrary schema. These stored mappings will allow LabNanny to create new data collection sessions on Databrary and populate them with videos and other data files. 

After we have file uploads working well, we will enable LabNanny to pull files from Databrary and save them locally. For example, when PLAY project staff assign a particular video to a specific lab for a particular coding pass (e.g., locomotion and physical activity), LabNanny (on Databrary) will generate a template Datavyu coding file with all the appropriate codes and links to code definitions (Project 4). The video and coding file template will be tagged for the assigned lab’s use, and LabNanny can then manage manual or automatic syncing to the assigned researcher’s designated local “download/coding” directory.

##### Comments

 … A prototype has been created that allows for browsing public assets and downloading them. We are also looking at this feature to replace/augment the ZIPPING on db since it is CPU intensive.

